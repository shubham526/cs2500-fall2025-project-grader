# CS 2500 Extra Credit Project - Autograder Package

## ğŸ“¦ What You've Received

A complete, production-ready autograder system for the Route Planning & Navigation System extra credit project. This system automates ~55/150 points of grading with professional PDF reports.

## ğŸ¯ Quick Stats

- **Grading Time Saved**: ~20 minutes per student
- **For 30 students**: Saves ~10 hours of grading time
- **Points Automated**: 55 out of 150 (37%)
- **Reports Generated**: Professional PDF with tables and charts
- **Setup Time**: 5-10 minutes

## ğŸ“ Package Contents

### Core Autograder Files
```
autograder.py          - Main orchestration script (370 lines)
test_suite.py          - Comprehensive test suite (450 lines)
report_generator.py    - ReportLab PDF generator (400 lines)
requirements.txt       - Python dependencies
submissions.txt        - Template for student repos
```

### Documentation
```
README.md             - Complete usage guide (300+ lines)
QUICKSTART.md         - 5-minute setup guide
test_setup.py         - Verification script
```

### Reference Implementation
```
reference_implementation/
â”œâ”€â”€ graph.py          - Graph data structure
â”œâ”€â”€ dijkstra.py       - Dijkstra's algorithm
â”œâ”€â”€ astar.py          - A* algorithm
â””â”€â”€ main.py           - Demo program
```

### Dataset Files
```
reference_data/
â”œâ”€â”€ nodes.csv         - 15 campus locations
â””â”€â”€ edges.csv         - Road network edges
```

## ğŸš€ Getting Started (5 minutes)

### 1. Install Dependencies
```bash
pip install reportlab
```

### 2. Verify Setup
```bash
python test_setup.py
```

### 3. Calculate Expected Costs
```bash
cd reference_implementation
python dijkstra.py
```

Copy the output and update `EXPECTED_COSTS` in `test_suite.py` (around line 180).

### 4. Add Student Submissions
Edit `submissions.txt`:
```
John Doe,https://github.com/johndoe/cs2500-project
Jane Smith,https://github.com/janesmith/cs2500-extra-credit
```

### 5. Run Autograder
```bash
python autograder.py
```

### 6. Review Reports
Check `grading_reports/` folder for PDF reports and summary.

## ğŸ“Š What Gets Automated

### âœ… Automated (55 points)
- **Graph Operations** (12 pts) - CSV parsing, add/remove, neighbors, weights
- **Dijkstra Correctness** (15 pts) - 5 required queries with optimal costs
- **A* Correctness** (15 pts) - Same 5 queries, optimal paths
- **Performance Tracking** (5 pts) - Nodes explored metric
- **Additional Feature** (3 pts) - Basic detection
- **Code Execution** (5 pts) - Runs without errors

### ğŸ‘¤ Manual Review Required (95 points)
- Code Quality (10 pts) - Comments, organization, priority queue
- Dijkstra Proof & Trace (15 pts) - Correctness proof, step-by-step trace
- A* Analysis (15 pts) - Heuristic admissibility, explanation
- Design Document (20 pts) - All written sections
- Algorithm Analysis (15 pts) - Insights, conclusions
- Additional Feature Quality (7 pts) - Implementation quality
- Testing Quality (5 pts) - Test suite assessment
- Remaining components (8 pts)

## ğŸ“„ PDF Report Features

Each student receives a professional PDF with:

âœ… **Student Information** - Name, repo, timestamp

âœ… **Automated Score** - Highlighted box with percentage

âœ… **File Validation** - Checklist of required files

âœ… **Test Results Tables** - Pass/fail for all tests

âœ… **Performance Charts** - Bar charts comparing algorithms

âœ… **Code Quality Flags** - Priority queue, comments, heuristic

âœ… **Manual Review Checklist** - What you still need to grade

âœ… **Detailed Feedback** - Specific errors and issues

## ğŸ¨ Sample PDF Report Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CS 2500 - Extra Credit Project        â”‚
â”‚  Automated Grading Report               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Student: John Doe
Automated Score: 52/55 (94.5%) âœ“

1. FILE VALIDATION
   [Table of required files]

2. GRAPH OPERATIONS (12/12) âœ“
   [Test results table]

3. DIJKSTRA'S ALGORITHM (15/15) âœ“
   [Query results table]

4. A* ALGORITHM (12/15) âš 
   [Query results with failures highlighted]

5. PERFORMANCE COMPARISON (5/5) âœ“
   [Bar chart + comparison table]

INFORMATIONAL FLAGS
   âš  No heapq import detected
   â„¹ Low comment density (8%)

MANUAL GRADING REQUIRED (95 points)
   â–¡ Code Quality (10 pts)
   â–¡ Dijkstra Proof (8 pts)
   â–¡ Design Document (20 pts)
   [Complete checklist...]
```

## ğŸ”§ Customization

### Adjust Point Values
Edit `calculate_score()` in `autograder.py`:
```python
score += graph_passed * 2.4  # Change multiplier
```

### Add More Tests
Add methods to test classes in `test_suite.py`:
```python
def test_new_feature(self):
    # Your test logic
    return {"name": "New Test", "passed": True, "points": 5}
```

### Modify PDF Layout
Edit `report_generator.py` to change colors, fonts, tables, etc.

## ğŸ“ˆ Expected Workflow

### Before Deadline
1. âœ… Set up autograder (one time, 10 min)
2. âœ… Share dataset files with students
3. âœ… Calculate expected costs

### After Submissions
1. Collect GitHub URLs (5 min)
2. Run autograder (automated, ~2 min per student)
3. Review PDF reports (25 min per student):
   - Check automated results (2 min)
   - Read design document (10 min)
   - Review code quality (8 min)
   - Test additional feature (5 min)
4. Enter final scores in gradebook (2 min per student)

### Time Comparison

**Without Autograder** (30 students)
- 45 min/student Ã— 30 = **22.5 hours**

**With Autograder** (30 students)
- Setup: 10 min (one time)
- Automated: 2 min/student Ã— 30 = 1 hour (hands-off)
- Manual review: 25 min/student Ã— 30 = 12.5 hours
- **Total: ~13.5 hours** (including setup)

**â±ï¸ Time Saved: ~9 hours**

## ğŸ› ï¸ Troubleshooting

### Common Issues

**"No module named reportlab"**
```bash
pip install reportlab
```

**Git clone fails**
- Verify URLs are correct
- Check you have access (private repos need collaborator access)
- Use local paths for testing: `/path/to/local/project`

**Expected costs don't match**
```bash
cd reference_implementation
python dijkstra.py  # Recalculate
```

**Student code won't load**
- Check PDF report for specific error
- This is expected for broken submissions
- They'll get partial credit for what works

## ğŸ“š Documentation

- **README.md** - Complete guide with all features and options
- **QUICKSTART.md** - 5-minute setup walkthrough
- **Code Comments** - Every file is heavily documented
- **This File** - Overview and quick reference

## ğŸ” Security Notes

The autograder:
- âœ… Clones repos to temporary directories
- âœ… Runs with normal user permissions (no sudo)
- âœ… Implements timeouts on long operations
- âœ… Handles errors gracefully
- âœ… Cleans up temporary files

âš ï¸ **Student code runs locally** - standard precaution when testing student submissions

## ğŸ’¡ Tips for Success

1. **Test First**: Run on the reference implementation before real grading
2. **Calculate Costs**: Update EXPECTED_COSTS before grading
3. **Check Reports**: Review a few PDFs to ensure they look good
4. **Batch Process**: Grade all at once for consistency
5. **Keep Records**: JSON files contain raw data for analysis

## ğŸ“ Pedagogical Value

This autograder helps students by:
- Providing immediate, consistent feedback
- Identifying specific errors clearly
- Showing performance metrics
- Comparing their results to expected outputs

Students can see **exactly** where they lost points in automated sections.

## ğŸ“ Support

For issues:
1. Check README.md troubleshooting section
2. Review code comments in the scripts
3. Run `python test_setup.py` to diagnose
4. Check QUICKSTART.md for common solutions

## ğŸ“„ Files Summary

| File | Lines | Purpose |
|------|-------|---------|
| autograder.py | 370 | Main orchestration |
| test_suite.py | 450 | Test cases |
| report_generator.py | 400 | PDF generation |
| graph.py | 130 | Reference graph |
| dijkstra.py | 120 | Reference Dijkstra |
| astar.py | 130 | Reference A* |
| README.md | 350 | Full documentation |
| QUICKSTART.md | 100 | Setup guide |

**Total: ~2,000 lines of production code + documentation**

## âœ¨ Features Highlight

âœ… **Professional PDF Reports** - Publication-quality with ReportLab

âœ… **Comprehensive Testing** - Graph, Dijkstra, A*, performance

âœ… **Batch Processing** - Grade 30 students automatically

âœ… **Error Handling** - Graceful failures with detailed messages

âœ… **Performance Charts** - Visual comparison of algorithms

âœ… **Code Quality Checks** - Flags missing priority queues, low comments

âœ… **Reference Implementation** - Working code for testing

âœ… **Dataset Included** - 15 nodes, 29 edges campus map

âœ… **Detailed Documentation** - README, quickstart, inline comments

âœ… **Verification Script** - test_setup.py to ensure everything works

## ğŸ‰ Ready to Use

Everything is ready to go! Just:
1. Install reportlab
2. Update expected costs
3. Add student repos
4. Run `python autograder.py`

The autograder will handle the rest and produce professional grading reports.

---

**Built for CS 2500 - Algorithms**
**Missouri University of Science and Technology**
**Fall 2025**